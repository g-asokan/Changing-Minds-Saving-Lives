{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    " \n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, EntitiesOptions, KeywordsOptions\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "\n",
    "import logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_file = \"comments.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "#df2 = df.groupby([\"Permalink\"]).sum()\n",
    "\n",
    "Permalink = df[\"Permalink\"]\n",
    "Comment = df[\"Comment\"]\n",
    "#print(Comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend([\"also\", \"and\", \"its\", \"bring\", \"got\", \"from\", \"lot\", \"rather\", \"even\", \"from\", \"but\",\"that\",\"in\",\"you\",\"who\",\"to\", \"of\", \"become\", \"thats\", \"looking\"])\n",
    "    words = [w for w in text if w not in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words related to Obama:  ['obama', 'texas', 'false', 'liberal', 'local', 'million', 'lying', 'months', 'plus', '2020', 'elderly']\n",
      "Words related to Trump:  ['trump', 'agenda', 'everyone', 'except', 'him', 'free', 'away', 'die', 'pos', 'next', 'person']\n",
      "Words related to riots:  ['riots', 'lives', 'together', 'outside', 'parks', 'decision', 'governor', 'cost', 'plan', 'lying', 'mayor']\n",
      "Words related to china:  ['china', 'soros', 'help', 'covid-19', 'night', 'charge', 'election', 'literally', 'water', 'died', \"'\"]\n",
      "Words related to massachusetts:  ['massachusetts', 'peaceably', 'fresno', 'psychos', 'keesters', 'privacy', 'skate', 'exceptions', 'trouble', 'transportation', 'alright']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "stop_clean = remove_stopwords(Comment)\n",
    "\n",
    "str_list = list(map(str, stop_clean)) # Converting all datatypes to strings\n",
    "porter = PorterStemmer()\n",
    "\n",
    "stemmed = []\n",
    "for s in str_list:\n",
    "    stemmed.append(porter.stem(s))\n",
    "\n",
    "#for x in new_list:\n",
    "    #print(type(x), x)\n",
    "\n",
    "tokens = []\n",
    "for i in stemmed:\n",
    "    i.lower()\n",
    "    tokens.append(word_tokenize(i))\n",
    "#print(tokens)\n",
    "model = Word2Vec(tokens, min_count=1, size=50, workers=3, window=2, sg=1)\n",
    "\n",
    "def similarity(word):\n",
    "    word_H=[word]\n",
    "    for i in range(10):\n",
    "        word_H.append((model.most_similar(word)[:10])[i][0])\n",
    "\n",
    "    return(word_H)\n",
    "print(\"Words related to Obama: \", similarity(\"obama\"))\n",
    "\n",
    "print(\"Words related to Trump: \", similarity(\"trump\"))\n",
    "\n",
    "print(\"Words related to riots: \", similarity(\"riots\"))\n",
    "\n",
    "print(\"Words related to china: \", similarity(\"china\"))\n",
    "\n",
    "print(\"Words related to massachusetts: \", similarity(\"massachusetts\"))\n",
    "# Examining some contentious words and their most similar words in the comments section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['england', 'seattle', 'minneapolis', 'miami', 'houston', 'detroit', 'america', 'afghanistan', 'houston', 'houston', 'vietnam', 'seattle', 'u.s.', 'minneapolis', 'sharpton', 'america', 'vietnam', 'chicago', 'vietnam', 'minnesota', 'america', 'baltimore', 'california', 'vietnam', 'baltimore', 'vietnam', 'missouri', 'killdozer', 'colorado', 'michigan', 'california', 'america', 'washington', 'california', 'america', 'california', 'u.s.', 'california', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'illinois', 'michigan', 'iowa', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'soooo', 'chicago', 'chicago', 'wisconsin', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'america', 'america', 'china', 'america', 'america', 'u.s.', 'massachusetts', 'florida', 'america', 'wuhan', 'china', 'china', 'america', 'america', 'washington', 'china', 'china', 'phoenix', 'america', 'america', 'florida', 'china', 'china', 'china', 'america', 'china', 'america', 'china', 'china', 'america', 'yaaay', 'china', 'china', 'chinia', 'america', 'texas', 'virginia', 'florida', 'commiefornia', 'florida', 'wisconsin', 'texas', 'mexico', 'mightmar', 'virginia', 'florida', 'texas', 'texas', 'arlington', 'iowa', 'germany', 'america', 'texas', 'michigan', 'texas', 'wuhan', 'economi', 'wuhan', 'wuhan', 'outta', 'michigan', 'america', 'america', 'america', 'china', 'america', 'italy', 'america', 'america', 'america', 'china', 'texas', 'america', 'california', 'kmiec', 'wuhan', 'wuhan', 'wuhan', 'china', 'wuhan', 'america', 'soooo', 'texas', 'italy', 'america', 'trenton', 'america', 'china', 'texas', 'florida', 'illinois', 'springfield', 'oregon', 'florida', 'america', 'idaho', 'illinois', 'california', 'california', 'china', 'america', 'japan', 'sweden', 'america', 'america', 'delaware', 'florida', 'america', 'america', 'wuhan', 'maryland', 'america', 'calif', 'michigan', 'pennsylvania', 'texas', 'texas', 'boston', 'michigan', 'california', 'minnesota', 'michigan', 'mexico', 'california', 'wisconsin', 'california', 'oklahoma', 'arizona', 'virginia', 'iowa', 'california', 'mexico', 'washington', 'massachusetts', 'washington', 'mexico', 'seattle', 'washington', 'pennsylvania', 'kommiefornia', 'washington', 'montana', 'montana', 'california', 'minnesota', 'minnesota', 'iowa', 'missouri', 'boston', 'ohio', 'california', 'america', 'uk', 'america', 'america', 'bronx', 'michigan', 'michigan', 'chad', 'california', 'france', 'jackwagon', 'turkey', 'wuhan', 'america', 'inconveni', 'america', 'america', 'arizona', 'outta', 'florida', 'arizona', 'georgia', 'georgia', 'mexico', 'commiefornia', 'cuba', 'oregon', 'california', 'commiefornia', 'phoenix', 'california', 'america', 'japan', 'u.s.', 'kenya', 'america', 'america', 'dallas', 'houston', 'mexico', 'america', 'montana', 'america', 'arizona', 'america', 'california', 'america', 'california', 'texas', 'illinois', 'california', 'texas', 'holland', 'sweden', 'tennessee', 'nebbia', 'manyyy', 'america', 'italy', 'america', 'dallas', 'georgia', 'florida', 'outta', 'moscow', 'america', 'wuhan', 'faruci', 'china', 'america', 'northrum', 'california', 'america', 'america', 'america', 'michigan', 'america', 'michigan', 'texas', 'kansas', 'wisconsin', 'kentucky', 'texas', 'california', 'california']\n"
     ]
    }
   ],
   "source": [
    "#Printing out the geographical locations only\n",
    "entities = []\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "flat = list(flatten(tokens))\n",
    "for word in flat:\n",
    "    doc = nlp(word) \n",
    "    for ent in doc.ents: \n",
    "        #print(ent.text, ent.start_char, ent.end_char, ent.label_) \n",
    "        if ent.label_ == \"GPE\":\n",
    "            entities.append(ent.text)\n",
    "print(entities)\n",
    "# Finding all the locations mentioned\n",
    "#entities=['england', 'seattle', 'minneapolis', 'miami', 'houston', 'detroit', 'america', 'afghanistan', 'houston', 'houston', 'vietnam', 'seattle', 'u.s.', 'minneapolis', 'sharpton', 'america', 'vietnam', 'chicago', 'vietnam', 'minnesota', 'america', 'baltimore', 'california', 'vietnam', 'baltimore', 'vietnam', 'missouri', 'killdozer', 'colorado', 'michigan', 'california', 'america', 'washington', 'california', 'america', 'california', 'u.s.', 'california', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'illinois', 'michigan', 'iowa', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'soooo', 'chicago', 'chicago', 'wisconsin', 'chicago', 'chicago', 'chicago', 'chicago', 'chicago', 'america', 'america', 'china', 'america', 'america', 'u.s.', 'massachusetts', 'florida', 'america', 'wuhan', 'china', 'china', 'america', 'america', 'washington', 'china', 'china', 'phoenix', 'america', 'america', 'florida', 'china', 'china', 'china', 'america', 'china', 'america', 'china', 'china', 'america', 'yaaay', 'china', 'china', 'chinia', 'america', 'texas', 'virginia', 'florida', 'commiefornia', 'florida', 'wisconsin', 'texas', 'mexico', 'mightmar', 'virginia', 'florida', 'texas', 'texas', 'arlington', 'iowa', 'germany', 'america', 'texas', 'michigan', 'texas', 'wuhan', 'economi', 'wuhan', 'wuhan', 'outta', 'michigan', 'america', 'america', 'america', 'china', 'america', 'italy', 'america', 'america', 'america', 'china', 'texas', 'america', 'california', 'kmiec', 'wuhan', 'wuhan', 'wuhan', 'china', 'wuhan', 'america', 'soooo', 'texas', 'italy', 'america', 'trenton', 'america', 'china', 'texas', 'florida', 'illinois', 'springfield', 'oregon', 'florida', 'america', 'idaho', 'illinois', 'california', 'california', 'china', 'america', 'japan', 'sweden', 'america', 'america', 'delaware', 'florida', 'america', 'america', 'wuhan', 'maryland', 'america', 'calif', 'michigan', 'pennsylvania', 'texas', 'texas', 'boston', 'michigan', 'california', 'minnesota', 'michigan', 'mexico', 'california', 'wisconsin', 'california', 'oklahoma', 'arizona', 'virginia', 'iowa', 'california', 'mexico', 'washington', 'massachusetts', 'washington', 'mexico', 'seattle', 'washington', 'pennsylvania', 'kommiefornia', 'washington', 'montana', 'montana', 'california', 'minnesota', 'minnesota', 'iowa', 'missouri', 'boston', 'ohio', 'california', 'america', 'uk', 'america', 'america', 'bronx', 'michigan', 'michigan', 'chad', 'california', 'france', 'jackwagon', 'turkey', 'wuhan', 'america', 'inconveni', 'america', 'america', 'arizona', 'outta', 'florida', 'arizona', 'georgia', 'georgia', 'mexico', 'commiefornia', 'cuba', 'oregon', 'california', 'commiefornia', 'phoenix', 'california', 'america', 'japan', 'u.s.', 'kenya', 'america', 'america', 'dallas', 'houston', 'mexico', 'america', 'montana', 'america', 'arizona', 'america', 'california', 'america', 'california', 'texas', 'illinois', 'california', 'texas', 'holland', 'sweden', 'tennessee', 'nebbia', 'manyyy', 'america', 'italy', 'america', 'dallas', 'georgia', 'florida', 'outta', 'moscow', 'america', 'wuhan', 'faruci', 'china', 'america', 'northrum', 'california', 'america', 'america', 'america', 'michigan', 'america', 'michigan', 'texas', 'kansas', 'wisconsin', 'kentucky', 'texas', 'california', 'california']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file2 = \"posts.csv\"\n",
    "df2 = pd.read_csv(csv_file2)\n",
    "\n",
    "Post = df2[\"Post\"]\n",
    "#print(Post)\n",
    "\n",
    "# Looking at the posts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_clean2 = remove_stopwords(Post)\n",
    "\n",
    "str_list2 = list(map(str, stop_clean2)) # Converting all datatypes to strings\n",
    "\n",
    "\n",
    "tokens2 = []\n",
    "for i in str_list2:\n",
    "    tokens2.append(word_tokenize(i))\n",
    "#print(tokens)\n",
    "\n",
    "def similarity2(word):\n",
    "    model = Word2Vec(tokens2, min_count=1, size=50, workers=3, window=3, sg=1)\n",
    "    word_H=[word]\n",
    "    for i in range(10):\n",
    "        word_H.append((model.most_similar(word)[:10])[i][0])\n",
    "\n",
    "    return(word_H)\n",
    "print(\"Words most similar to unrest\", similarity2(\"unrest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
